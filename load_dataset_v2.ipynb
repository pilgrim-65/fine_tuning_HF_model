{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45921d14-ea20-41ec-8acb-fb3ecaf4c34e",
   "metadata": {},
   "source": [
    "# IberLEF 2023 Task - PoliticEs. Political ideology detection in Spanish texts\n",
    "\n",
    "Datasources:\n",
    "\n",
    "[https://portal.odesia.uned.es/en/dataset/politices-2023](https://portal.odesia.uned.es/en/dataset/politices-2023)\n",
    "\n",
    "[https://codalab.lisn.upsaclay.fr/competitions/10173#learn_the_details-get_starting_kit](https://codalab.lisn.upsaclay.fr/competitions/10173#learn_the_details-get_starting_kit)\n",
    "\n",
    "Using Trainer class with CUDA parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152764e4",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f01510-3b7c-4125-bd7e-18478a3761c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad8909b0b9b4c8e8ea7da50dc9a20e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8bce5d950943d5b7e8da6d5db4897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'gender', 'profession', 'ideology_binary', 'ideology_multiclass', 'tweet'],\n",
       "        num_rows: 14400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'gender', 'profession', 'ideology_binary', 'ideology_multiclass', 'tweet'],\n",
       "        num_rows: 3600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "data_files = {\"train\": \"data/development.csv\", \n",
    "              \"test\": \"data/development_test.csv\"}\n",
    "politic_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "politic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e86d6",
   "metadata": {},
   "source": [
    "In order to understand the data, we can perform EDA (Exploratory Data Analysis) on the dataset using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9313d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = politic_dataset[\"train\"].to_pandas()\n",
    "df_test = politic_dataset[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9502c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>ideology_binary</th>\n",
       "      <th>ideology_multiclass</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00369358fac3b8d42845f82f0c3ececc</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>@user Escribió un libro resultón, con gracejo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00369358fac3b8d42845f82f0c3ececc</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>@user Lo prometido es deuda. Aquí la foto: .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00369358fac3b8d42845f82f0c3ececc</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>@user Bastante ñoña. Me jarté a llorar. De lo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00369358fac3b8d42845f82f0c3ececc</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>@user No sé nada acerca de eso, pero está clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00369358fac3b8d42845f82f0c3ececc</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>@user ¿En qué medio tienen su podcast esos, di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              label gender  profession ideology_binary  \\\n",
       "0  00369358fac3b8d42845f82f0c3ececc   male  journalist            left   \n",
       "1  00369358fac3b8d42845f82f0c3ececc   male  journalist            left   \n",
       "2  00369358fac3b8d42845f82f0c3ececc   male  journalist            left   \n",
       "3  00369358fac3b8d42845f82f0c3ececc   male  journalist            left   \n",
       "4  00369358fac3b8d42845f82f0c3ececc   male  journalist            left   \n",
       "\n",
       "  ideology_multiclass                                              tweet  \n",
       "0                left  @user Escribió un libro resultón, con gracejo,...  \n",
       "1                left       @user Lo prometido es deuda. Aquí la foto: .  \n",
       "2                left  @user Bastante ñoña. Me jarté a llorar. De lo ...  \n",
       "3                left  @user No sé nada acerca de eso, pero está clar...  \n",
       "4                left  @user ¿En qué medio tienen su podcast esos, di...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f4bee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df_train.ideology_binary.value_counts()\n",
    "max_value = counts.max() * 1.1  # Add some space above the highest bar\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "ax = df_train.ideology_binary.value_counts().plot(kind=\"bar\",\n",
    "                                                  figsize=(4,3), \n",
    "                                                  ylim=(0, max_value),\n",
    "                                                  color=['red', 'blue'])\n",
    "# Add percentage labels\n",
    "for i, (count, pct) in enumerate(zip(counts, percentages)):\n",
    "    ax.text(i, count, f'{pct:.0f}%', ha='center', va='bottom', fontsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45146cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|    | label                            | gender   | profession   | ideology_binary   | ideology_multiclass   | tweet                                                                                                                                                                                                                                                                                       |\\n|---:|:---------------------------------|:---------|:-------------|:------------------|:----------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n|  0 | 00369358fac3b8d42845f82f0c3ececc | male     | journalist   | left              | left                  | @user Escribió un libro resultón, con gracejo, que mueve sentimientos por doquier. La invitaron a hablar de ello ante Presidencia, lo preparó bien para impactar. Lo logró. La intelectualidad de izquierdas, solita, hizo el resto. Le hizo la publi, le generó el hueco, la consagró.     |\\n|  1 | 00369358fac3b8d42845f82f0c3ececc | male     | journalist   | left              | left                  | @user Lo prometido es deuda. Aquí la foto: .                                                                                                                                                                                                                                                |\\n|  2 | 00369358fac3b8d42845f82f0c3ececc | male     | journalist   | left              | left                  | @user Bastante ñoña. Me jarté a llorar. De lo más terapéutico.                                                                                                                                                                                                                              |\\n|  3 | 00369358fac3b8d42845f82f0c3ececc | male     | journalist   | left              | left                  | @user No sé nada acerca de eso, pero está claro que vulnerar un \\'Off the record\\' no es manera de cuidar a periodistas \"cercanos\", como debe hacer un portavoz en respeto a su responsabilidad organizativa. Eso es de primero de comunicación, y a Iglesias no se le escapa, te lo aseguro. |\\n|  4 | 00369358fac3b8d42845f82f0c3ececc | male     | journalist   | left              | left                  | @user ¿En qué medio tienen su podcast esos, dice Ud.?                                                                                                                                                                                                                                       |'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head().to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a0527",
   "metadata": {},
   "source": [
    "This distribution shows a slight imbalance ($56/46$), which is not severe enough to produce a low F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b82ddc-eacb-48b3-9dd8-9437f37d7a65",
   "metadata": {},
   "source": [
    "## 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, # For tokenization\n",
    "    DataCollatorWithPadding, # For dynamic padding\n",
    "    AutoModelForSequenceClassification, # For loading pre-trained model\n",
    "    TrainingArguments, # For setting training arguments\n",
    "    Trainer # Transformer Trainer class\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "checkpoint = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.model_max_length = 128 # For comparison with Robertuito model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "\n",
    "load_dotenv(\".env\")  # Load environment variables WANDB_API_KEY \n",
    "wandb.init(project=\"transformers-fine-tuning\", name=f\"politicES-{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df438813-48b6-4014-ad0b-84025bc205f9",
   "metadata": {},
   "source": [
    "## 3. Define the Classification Task and Labels\n",
    "The target column is **'ideology_binary'**. We need to map the labels to IDs,\n",
    "where 'ideology_binary' has two classes: 'left' and 'right'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6670883-331d-4dc2-8fa5-ece8f4babba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the label mappings \n",
    "label_to_id = {\"left\": 0, \"right\": 1}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "num_labels = len(label_to_id)\n",
    "\n",
    "# Load the model with the correct number of labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d239bf-2edd-4ce0-bdbd-07887e64c873",
   "metadata": {},
   "source": [
    "We receive a warning because the choosed model has not been pretrained on classifying texts, the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45d5af",
   "metadata": {},
   "source": [
    "\n",
    "The **'label'** column is usually the one used by the Trainer, \n",
    "so we will map the target column **'ideology_binary'** to **'label'**. In the PoliticES dataset the **'label'** column corresponds to an id of the tweet, so we have to rename it. \n",
    "\n",
    "Moreover, the parameter **remove_unused_columns** of the Trainer class defaults to True, we don't need to take care of removing the columns unused by the model forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c134c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = politic_dataset.remove_columns(['label', 'gender', 'profession',  'ideology_multiclass'])\n",
    "politic_dataset = politic_dataset.rename_column(\"label\", \"id\")\n",
    "politic_dataset = politic_dataset.rename_column(\"ideology_binary\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97029137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'gender', 'profession', 'label', 'ideology_multiclass', 'tweet'],\n",
       "        num_rows: 14400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'gender', 'profession', 'label', 'ideology_multiclass', 'tweet'],\n",
       "        num_rows: 3600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f698d61-d8cf-4d1f-92d1-25daf3151310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def tokenize_and_encode_labels(examples):\n",
    "    # Tokenize the input text (tweet)\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tweet\"], \n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Map the political ideology string label to an integer ID for training\n",
    "    tokenized_inputs[\"label\"] = [label_to_id[label] for label in examples[\"label\"]]\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_dataset = politic_dataset.map(tokenize_and_encode_labels, batched=True) \n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # Dynamic padding\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4ff84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value('string'),\n",
       " 'gender': Value('string'),\n",
       " 'profession': Value('string'),\n",
       " 'label': Value('int64'),\n",
       " 'ideology_multiclass': Value('string'),\n",
       " 'tweet': Value('string'),\n",
       " 'input_ids': List(Value('int32')),\n",
       " 'token_type_ids': List(Value('int8')),\n",
       " 'attention_mask': List(Value('int8'))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018672a",
   "metadata": {},
   "source": [
    "## 4. Define Evaluation Metrics\n",
    "\n",
    "Precission measures how many of the samples predicted as positive are actually positive:\n",
    "\n",
    "$Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "Recall measures how many of the positive samples are captured by the positive samples are captured by the positive predictions:\n",
    "\n",
    "$Recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "And one way to summarize both metrics is the f1-score, which is the armonic mean of precission and recall:\n",
    "\n",
    "$F1 = 2 \\times \\large \\frac{precision\\times recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c9c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Load the necessary metrics from the 'evaluate' library\n",
    "# We can load the standard 'precision', 'recall', and 'f1' metrics once\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute precision, recall, and F1 macro score for a Hugging Face Trainer.\n",
    "\n",
    "    Args:\n",
    "        eval_pred (EvalPrediction): A tuple (predictions, labels) provided by Trainer.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'precision', 'recall', and 'f1-macro' metrics.\n",
    "    \"\"\"\n",
    "    # The EvalPrediction object contains (predictions, label_ids)\n",
    "    logits, labels = eval_pred \n",
    "\n",
    "    # 1. Convert logits to class predictions\n",
    "    # Predictions are the index of the highest logit value across the class axis (-1)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # 2. Compute the metrics using the macro average\n",
    "    \n",
    "    # F1 Score\n",
    "    f1_result = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    # Precision\n",
    "    precision_result = metric_precision.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    # Recall\n",
    "    recall_result = metric_recall.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    # 3. Return the results dictionary\n",
    "    return {\n",
    "        \"precision\": precision_result[\"precision\"],\n",
    "        \"recall\": recall_result[\"recall\"],\n",
    "        \"f1-macro\": f1_result[\"f1\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ccaece",
   "metadata": {},
   "source": [
    "## 5. Configure Trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce51ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "\n",
    "output_dir = f\"./results_{model_name}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,                # Output directory\n",
    "    num_train_epochs=5,                   # Total number of training epochs\n",
    "    per_device_train_batch_size=32,       # Batch size per device during training\n",
    "    per_device_eval_batch_size=32,        # Batch size for evaluation\n",
    "    fp16=True,                            # Use mixed precision\n",
    "    eval_strategy=\"epoch\",                # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                # Save a checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True,          # Load the best model found during training\n",
    "    metric_for_best_model=\"eval_loss\",    # Metric to track for best model\n",
    "    disable_tqdm=False,                   # Enable tqdm progress bars\n",
    "    report_to=\"wandb\"                     # Report metrics to Weights & Biases\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae3cd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.001)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43924533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/2250 04:59 < 01:14, 6.01 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.632238</td>\n",
       "      <td>0.638366</td>\n",
       "      <td>0.641435</td>\n",
       "      <td>0.638101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.657227</td>\n",
       "      <td>0.670474</td>\n",
       "      <td>0.671647</td>\n",
       "      <td>0.670965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.655356</td>\n",
       "      <td>0.647217</td>\n",
       "      <td>0.648764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>1.625522</td>\n",
       "      <td>0.661496</td>\n",
       "      <td>0.663006</td>\n",
       "      <td>0.662066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.3447630596160889, metrics={'train_runtime': 299.7589, 'train_samples_per_second': 240.193, 'train_steps_per_second': 7.506, 'total_flos': 2339419059851520.0, 'train_loss': 0.3447630596160889, 'epoch': 4.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2bdcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__backends',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__firstlineno__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activate_neftune',\n",
       " '_add_sm_patterns_to_gitignore',\n",
       " '_created_lr_scheduler',\n",
       " '_deactivate_neftune',\n",
       " '_determine_best_metric',\n",
       " '_evaluate',\n",
       " '_finish_current_push',\n",
       " '_fsdp_qlora_plugin_updates',\n",
       " '_gather_and_numpify',\n",
       " '_get_collator_with_removed_columns',\n",
       " '_get_dataloader',\n",
       " '_get_eval_sampler',\n",
       " '_get_learning_rate',\n",
       " '_get_output_dir',\n",
       " '_get_train_sampler',\n",
       " '_globalstep_last_logged',\n",
       " '_hp_search_setup',\n",
       " '_inner_training_loop',\n",
       " '_issue_warnings_after_load',\n",
       " '_load_best_model',\n",
       " '_load_callback_state',\n",
       " '_load_from_checkpoint',\n",
       " '_load_optimizer_and_scheduler',\n",
       " '_load_rng_state',\n",
       " '_load_scaler',\n",
       " '_loggers_initialized',\n",
       " '_maybe_log_save_evaluate',\n",
       " '_memory_tracker',\n",
       " '_move_model_to_device',\n",
       " '_nested_gather',\n",
       " '_prepare_input',\n",
       " '_prepare_inputs',\n",
       " '_push_from_checkpoint',\n",
       " '_remove_unused_columns',\n",
       " '_report_to_hp_search',\n",
       " '_rotate_checkpoints',\n",
       " '_save',\n",
       " '_save_checkpoint',\n",
       " '_save_optimizer_and_scheduler',\n",
       " '_save_rng_state',\n",
       " '_save_scaler',\n",
       " '_save_tpu',\n",
       " '_set_signature_columns_if_needed',\n",
       " '_signature_columns',\n",
       " '_sorted_checkpoints',\n",
       " '_total_loss_scalar',\n",
       " '_train_batch_size',\n",
       " '_trial',\n",
       " '_tune_save_checkpoint',\n",
       " '_wrap_model',\n",
       " 'accelerator',\n",
       " 'add_callback',\n",
       " 'args',\n",
       " 'autocast_smart_context_manager',\n",
       " 'call_model_init',\n",
       " 'callback_handler',\n",
       " 'can_return_loss',\n",
       " 'compare_trainer_and_checkpoint_args',\n",
       " 'compute_loss',\n",
       " 'compute_loss_context_manager',\n",
       " 'compute_loss_func',\n",
       " 'compute_metrics',\n",
       " 'control',\n",
       " 'create_accelerator_and_postprocess',\n",
       " 'create_model_card',\n",
       " 'create_optimizer',\n",
       " 'create_optimizer_and_scheduler',\n",
       " 'create_scheduler',\n",
       " 'current_flos',\n",
       " 'data_collator',\n",
       " 'deepspeed',\n",
       " 'eval_dataset',\n",
       " 'evaluate',\n",
       " 'evaluation_loop',\n",
       " 'floating_point_ops',\n",
       " 'gather_function',\n",
       " 'get_batch_samples',\n",
       " 'get_decay_parameter_names',\n",
       " 'get_eval_dataloader',\n",
       " 'get_learning_rates',\n",
       " 'get_num_trainable_parameters',\n",
       " 'get_optimizer_cls_and_kwargs',\n",
       " 'get_optimizer_group',\n",
       " 'get_test_dataloader',\n",
       " 'get_train_dataloader',\n",
       " 'hp_name',\n",
       " 'hp_search_backend',\n",
       " 'hub_model_id',\n",
       " 'hyperparameter_search',\n",
       " 'init_hf_repo',\n",
       " 'ipex_optimize_model',\n",
       " 'is_deepspeed_enabled',\n",
       " 'is_fsdp_enabled',\n",
       " 'is_fsdp_xla_enabled',\n",
       " 'is_fsdp_xla_v1_enabled',\n",
       " 'is_fsdp_xla_v2_enabled',\n",
       " 'is_in_train',\n",
       " 'is_local_process_zero',\n",
       " 'is_model_parallel',\n",
       " 'is_tp_enabled',\n",
       " 'is_world_process_zero',\n",
       " 'label_names',\n",
       " 'label_smoother',\n",
       " 'log',\n",
       " 'log_metrics',\n",
       " 'lr_scheduler',\n",
       " 'metrics_format',\n",
       " 'model',\n",
       " 'model_accepts_loss_kwargs',\n",
       " 'model_init',\n",
       " 'model_wrapped',\n",
       " 'neftune_noise_alpha',\n",
       " 'num_examples',\n",
       " 'num_tokens',\n",
       " 'optimizer',\n",
       " 'optimizer_cls_and_kwargs',\n",
       " 'place_model_on_device',\n",
       " 'pop_callback',\n",
       " 'predict',\n",
       " 'prediction_loop',\n",
       " 'prediction_step',\n",
       " 'preprocess_logits_for_metrics',\n",
       " 'processing_class',\n",
       " 'propagate_args_to_deepspeed',\n",
       " 'push_to_hub',\n",
       " 'remove_callback',\n",
       " 'save_metrics',\n",
       " 'save_model',\n",
       " 'save_state',\n",
       " 'set_initial_training_values',\n",
       " 'state',\n",
       " 'store_flos',\n",
       " 'tokenizer',\n",
       " 'torch_jit_model_eval',\n",
       " 'train',\n",
       " 'train_dataset',\n",
       " 'training_step',\n",
       " 'use_apex',\n",
       " 'use_cpu_amp']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25ab1355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='339' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 23:51:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6322383880615234,\n",
       " 'eval_precision': 0.6383659903599292,\n",
       " 'eval_recall': 0.6414347165991903,\n",
       " 'eval_f1-macro': 0.6381009141921545,\n",
       " 'eval_runtime': 3.6098,\n",
       " 'eval_samples_per_second': 997.286,\n",
       " 'eval_steps_per_second': 31.304,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b89ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6322\n",
      "eval_precision: 0.6384\n",
      "eval_recall: 0.6414\n",
      "eval_f1-macro: 0.6381\n",
      "eval_runtime: 3.7007\n",
      "eval_samples_per_second: 972.7890\n",
      "eval_steps_per_second: 30.5350\n",
      "epoch: 4.0000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
